\input{macros}

%#############################################################################################################%
%#############################################################################################################%
%#############################################################################################################%

\title{Distributing the Heat Equation}
\author{Tom Cornebize \and Yassine Hamoudi}
\date{Sunday, December 7th 2014}

\begin{document}

\maketitle

%#############################################################################################################%
%#############################################################################################################%
%#############################################################################################################%

\section{Cellular automata}

%#############################################################################################################%

\subsection*{Question 1}

\begin{lemma}
  \label{nextStep}
  $N^2$ applications of function $\delta$ are necessary to compute $X^t$ from $X^{t-1}$.
\end{lemma}

\begin{proof}
 Each cell $X^{t}_{i,j}$ needs one application of $\delta$ to be computed from $X^{t-1}_{i,j}$. There are $N^2$ cells, so $N^2$ applications of $\delta$ are needed.
\end{proof}

\begin{prop}
  $tN^2$ applications of function $\delta$ are necessary to compute $X^t$ on \textlbrackdbl $0,N-1$ \textrbrackdbl$^2$.
\end{prop}

\begin{proof}
 $X^t$ is obtained after $t$ applications of $\ddelta$ on $X^0$. Each application needs $N^2$ calls to $\delta$ according to lemma \ref{nextStep}. The whole computation needs $tN^2$ applications of $\delta$.
\end{proof}

%#############################################################################################################%

\subsection*{Question 2}

Let $p^2$ be the number of processors.

For the sake of simplicity, we will suppose that $p$ divides $N$. Take $n = \frac{N}{p}$.

We divide the grid into square zones of size $n$. Each of this zones is given to one processor, which stores the data in its own memory and performs the computation of $\delta$ for all its cells. See figure \ref{q2:draw} for an example.

At each step of computation, each processor updates its sub-matrix cells using a temporary sub-matrix that replaces the old one once the computation step is finished. Indeed,  if we update the cells ``in place'', we overwrite values that are still necessary to compute other cells.

The computation of $\delta$ for the cells at the edges of the zones requires communication to retrieve the current states of their neighbours in other zones.

\begin{figure}
\caption{Graphical representation of the topology for $N=6$ and $p^2=9$.}
\label{q2:draw}
\begin{center}
\begin{tikzpicture}
    \tikzstyle{case}=[draw, minimum height=1cm, minimum width=1cm, thick, fill=white, anchor=south west];
    \tikzstyle{redcase}=[draw, minimum height=2.4cm, minimum width=2.4cm, thick, fill=none, draw=red, anchor=south west];

    \foreach \x in {0,...,5} {
        \foreach \y in {0,...,5} {
            \node[case] at (1.2*\y,1.2*\x) {};
        }
    }
    \foreach \x in {0,...,2} {
        \foreach \y in {0,...,2} {
            \node[redcase] at (2.4*\y-0.1,2.4*\x-0.1) {};
        }
    }
\end{tikzpicture}
\end{center}
\end{figure}

%#############################################################################################################%

\subsection*{Question 3}

We assume that $X^t$ is given as an array $PREV$ of size $(n+2) \times (n+2)$, where $X^t_{i,j}$
is written in $PREV[i][j]$ and where $PREV[i][j]$ are dummy values for $i \in \set{0,n+1}$ or $j \in \set{0,n+1}$.

We also assume that the order of messages is preserved.

Let $$\delta(PREV,i,j) = \delta \left( \begin{array}{ | c | c | c |} \hline

  PREV[i-1,j-1] & PREV[i-1,j] & PREV[i-1,j+1] \\ \hline

  PREV[i,j-1] & PREV[i,j] & PREV[i+1,j+1] \\ \hline

  PREV[i+1,j-1] & PREV[i+1,j] & PREV[i+1,j+1] \\ \hline

 \end{array} \right)$$

We consider functions \texttt{Send\_X} (resp. \texttt{Receive\_X}) for \texttt{X = Up, Down, Left, Right} which sends (resp. receives) to (resp. from) the corresponding processor. 
We suppose that this function has a time cost of $1$ and a communication cost of $L+b$ where $L$ is the latency and $b$ the bandwidth.

We also consider functions to send an entire row (resp. column) as one single message, to decrease the overall latency. For instance, \texttt{Send\_Down\_Row(n,PREV)} will send to the down processor the $\text{n}^{th}$ row, whereas \texttt{Send\_Up\_Row(0,PREV)} will receive from the up processor a row, which will be stored as the $\text{0}^{th}$ row.
We suppose that this function has a time cost of $n$ and a communication cost of $L+nb$ where $L$ is the latency, $b$ the bandwidth, and $n$ the size of the row/column.

\begin{algorithm}[H]
\SetKwFunction{sndup}{Send\_Up}
\SetKwFunction{snddown}{Send\_Down}
\SetKwFunction{sndleft}{Send\_Left}
\SetKwFunction{sndright}{Send\_Right}
\SetKwFunction{rcvup}{Receive\_Up}
\SetKwFunction{rcvdown}{Receive\_Down}
\SetKwFunction{rcvleft}{Receive\_Left}
\SetKwFunction{rcvright}{Receive\_Right}
\SetKwFunction{sndupr}{Send\_Up\_Row}
\SetKwFunction{snddownr}{Send\_Down\_Row}
\SetKwFunction{sndleftc}{Send\_Left\_Column}
\SetKwFunction{sndrightc}{Send\_Right\_Column}
\SetKwFunction{rcvupr}{Receive\_Up\_Row}
\SetKwFunction{rcvdownr}{Receive\_Down\_Row}
\SetKwFunction{rcvleftc}{Receive\_Left\_Column}
\SetKwFunction{rcvrightc}{Receive\_Right\_Column}
\DontPrintSemicolon
\LinesNotNumbered
\KwIn{PREV: array[0..n+1,0..n+1] of real}
\KwOut{NEXT: array[0..n+1,0..n+1] of real}
\tcc{Columns and row}
\sndleftc{1,PREV}\;
\sndrightc{n,PREV}\;
\sndupr{1,PREV}\;
\snddownr{n,PREV}\;
\rcvleftc{0,PREV}\;
\rcvrightc{n+1,PREV}\;
\rcvupr{0,PREV}\;
\rcvdownr{n+1,PREV}\;
\tcc{Corners}
\sndup{PREV[1][0]}\;
\sndup{PREV[1][n+1]}\;
\snddown{PREV[n][0]}\;
\snddown{PREV[n][n+1]}\;
\rcvup{PREV[0][0]}\;
\rcvup{PREV[0][n+1]}\;
\rcvdown{PREV[n+1][0]}\;
\rcvdown{PREV[n+1][n+1]}\;
\caption{Stencil algorithm on a toric 2D grid\label{algoq3}}
\tcc{Computation of $\delta$}
\For{i=1 \textbf{to} n}{
    \For{j=1 \textbf{to} n}{
        $NEXT[i][j] = \delta(PREV,i,j)$\;
    }
}
\end{algorithm}

Time complexity: $8(n+1) + n^2 \text{cost}(\delta) = 8(\frac{N}{p}+1) + \left(\frac{N}{p}\right)^2 \text{cost}(\delta) = \cplx{\left(\frac{N}{p}\right)^2}$ if $\text{cost}(\delta) = \cplx{1}$.

Communication complexity (one processor): $8(L+nb+L+1) = 8(2L+\frac{N}{p}b+1)$.

Communication complexity (all processors): $8p^2(2L+\frac{N}{p}b+1) = 8(2p^2L+Npb+p^2)$.

\medbreak

\todo{Non-toric grid? Ring topology? Don't know a nice way to do this...}

%#############################################################################################################%
%#############################################################################################################%

\section{Average automata}

%#############################################################################################################%

\subsection*{Question 4}
 
 See the implementation in file \texttt{average.c}.
  
%#############################################################################################################%

\subsection*{Question 5}
 
\begin{prop}
 In the case of a \textit{p-average automaton}, $\ddelta$ is linear.
\end{prop}

\begin{proof}
 Let $\ddelta$ be the global transition function of a \textit{p-average automaton}. To prove that $\ddelta$ is linear, it suffices to prove that the local transition function $\delta$ is linear:
 
 \[ \delta \left( \begin{array}{ | c | c | c |} \hline
  a & b & c \\ \hline
  d & e & f \\ \hline
  g & h & i \\ \hline
 \end{array} \right) = (1-p) \cdot e+p \cdot \frac{b+d+f+h}{4}\]
 
 Let consider a real $k \in \RR$ and two local configurations $\begin{array}{ | c | c | c |} \hline
  a & b & c \\ \hline
  d & e & f \\ \hline
  g & h & i \\ \hline
 \end{array}$ and $\begin{array}{ | c | c | c |} \hline
  a' & b' & c' \\ \hline
  d' & e' & f' \\ \hline
  g' & h' & i' \\ \hline
 \end{array}$. We have:
 
 \[\begin{split}
 \delta \left( k \cdot \begin{array}{ | c | c | c |} \hline
  a & b & c \\ \hline
  d & e & f \\ \hline
  g & h & i \\ \hline
 \end{array} + \begin{array}{ | c | c | c |} \hline
  a' & b' & c' \\ \hline
  d' & e' & f' \\ \hline
  g' & h' & i' \\ \hline
 \end{array} \right) & = (1-p) \cdot (k \cdot e+e') + p \cdot \frac{(k \cdot b+b')+(k \cdot d+d')+(k \cdot f+f')+(k \cdot h+h')}{4}  \\
		     & = k \cdot \left( (1-p) \cdot e+p \cdot \frac{b+d+f+h}{4} \right) + (1-p) \cdot e'+p \cdot \frac{b'+d'+f'+h'}{4} \\
		     & = k \cdot \delta \left( \begin{array}{ | c | c | c |} \hline
  a & b & c \\ \hline
  d & e & f \\ \hline
  g & h & i \\ \hline
 \end{array} \right) + \delta \left( \begin{array}{ | c | c | c |} \hline
  a' & b' & c' \\ \hline
  d' & e' & f' \\ \hline
  g' & h' & i' \\ \hline
 \end{array} \right)      
 \end{split}\]
 
Thus $\delta$ is linear, and $\ddelta$ too.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%ù

\begin{defi}
 For $0 \leq i,j \leq N-1$ we define the matrix $E^{i,j}$ such that $E^{i,j}_{i,j} = 1$ and $E^{i,j}_{k,l} = 0$ otherwise.
\end{defi}

\begin{lemma}
 For all $0 \leq i, j, k, l \leq N-1$, $\ddeltat(E^{i,j})_{k,l} = \ddeltat(E^{0,0})_{k-i,l-j}$ (indices are taken modulo $N$). Thus, knowing $\ddeltat(E^{0,0})$ we obtain $\ddeltat(E^{i,j})$ in constant time.
\end{lemma}

Now let's consider a configuration $X$. We have : $X = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X_{i,j} \cdot E^{i,j}$. Since $\ddelta$ is linear, for all t : 
\[ \ddeltat (X) = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X_{i,j} \cdot \ddeltat (E^{i,j})\]
 
Moreover : 
\begin{equation}
 \label{expanddelta}
 \begin{split}
    \ddeltatt (X) & = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X_{i,j} \cdot \ddeltatt (E^{i,j}) \\
		  & = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X_{i,j} \cdot \ddeltat(\ddeltat (E^{i,j})) \\
		  & = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X_{i,j} \sum_{k=0}^{N-1} \sum_{l=0}^{N-1} \ddeltat (E^{i,j})_{k,l} \cdot \ddeltat (E^{k,l}) \\
		  & = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X_{i,j} \sum_{k=0}^{N-1} \sum_{l=0}^{N-1} \ddeltat (E^{0,0})_{k-i,l-i} \cdot \ddeltat (E^{k,l})
 \end{split}
\end{equation}

Thus, for all $0 \leq m, n \leq N-1$:
\begin{equation}
 \label{aveq}
 \begin{split}
    \ddeltatt (X)_{m,n} & = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X_{i,j} \sum_{k=0}^{N-1} \sum_{l=0}^{N-1} \ddeltat (E^{0,0})_{k-i,l-i} \cdot \ddeltat (E^{k,l})_{m,n} \\
                        & = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X_{i,j} \sum_{k=0}^{N-1} \sum_{l=0}^{N-1} \ddeltat (E^{0,0})_{k-i,l-i} \cdot \ddeltat (E^{0,0})_{m-k,n-l}
 \end{split}
\end{equation}

Especially, for $X = E^{0,0}$:
\begin{equation}
 \label{avequnit}
 \begin{split}
    \ddeltatt (E^{0,0})_{m,n} & = \sum_{k=0}^{N-1} \sum_{l=0}^{N-1} \ddeltat (E^{0,0})_{k,l} \cdot \ddeltat (E^{0,0})_{m-k,n-l}
 \end{split}
\end{equation}

\begin{prop}
 Equations \ref{aveq} and \ref{avequnit} enable us to compute $\ddeltat(X)$ in time $O(log(t))$ for a fixed $N$.
\end{prop}

\begin{proof}
For computing $\ddeltatt(X)$ we need to compute $\ddeltat(E^{0,0})$ using equation \ref{avequnit} and then apply equation \ref{aveq} to get $\ddeltatt(X)$. The algorithm is:

\begin{algorithm}[H]
\DontPrintSemicolon
\LinesNotNumbered
\KwIn{t, X}
\KwOut{$\ddeltat(X)$}
\caption{Fast iteration on average automaton\label{algoq5}}
$R \leftarrow E^{0,0}$; \\
\For{i=1 \textbf{to} $\log(t) - 1$}{
    Compute $R \leftarrow \delta^{\dag^{2^i}}(E^{0,0})$ using $\delta^{\dag^{2^{i-1}}}(E^{0,0})$ (previous value of $R$) and equation \ref{avequnit}
}
Compute and return $\ddeltat(X)$ using $R = \delta^{\dag^{t/2}}(E^{0,0})$ and equation \ref{aveq}
\end{algorithm}

 Let $T'(t)$ be the time needed to compute $\ddeltat(E^{0,0})$. According to equation \ref{avequnit} we have:
 \[\begin{split}
    T'(t) & = T'(t/2) + O(1) \\
         & = O(\log(t))
   \end{split}
\]
 
 Now let $T(t)$ be the time needed to compute $\ddeltat(X)$. According to equation \ref{aveq} and previous remarks, we have:
 \[\begin{split}
    T(t) & = T'(t/2) + O(1) \\
	 & = O(\log(t))
   \end{split}
\]
 
 Thus, applying the operations described in equations \ref{aveq} and \ref{avequnit}, we can compute $\ddeltat(X)$ in time $O(\log(t))$. 
\end{proof}

\begin{prop}
 The time complexity $T_r(t,N)$ in terms of both $t$ and $N$ is $T_r(t,N) = O(N^4 \cdot \log(t) + N^6)$.
\end{prop}

\begin{proof}
  Let $T_e(t,N)$ be the time needed to compute $\ddeltat(E^{0,0})$. According to equation \ref{avequnit} we have:
 \[\begin{split}
    T_e(t) & = T_e(t/2) + N^2 \cdot N^2 \text{ (there are } N^2 \text{ cells and each one needs to perform } N^2 \text{ sums)} \\
         & = O(N^4 \cdot \log(t))
   \end{split}
\]  
  
  According to equation \ref{aveq} and the previous algorithm, knowing $\delta^{\dag^{t/2}}(E^{0,0})$ it remains to perform for each cell the four sums described in equation \ref{aveq} (it takes time $O(N^4)$ per cell). Finally, we have:
  \[ T_r(t,N) = N^2 \cdot N^4 + T_e(t/2,N)\]
  
  Thus: $T_r(t,N) = O(N^4 \cdot \log(t) + N^6)$.
\end{proof}

\begin{prop}
 The space complexity $T_s(t,N)$ in terms of both $t$ and $N$ is $T_s(t,N) = O(N^2)$.
\end{prop}

\begin{proof}
 We need $N^2$ space to store the initial matrix.

 When we compute $\delta^{\dag^{2^i}}(E^{0,0})$ using $\delta^{\dag^{2^{i-1}}}(E^{0,0})$, we need to use $N^2$ space to store $\delta^{\dag^{2^i}}$. However, the space used by $\delta^{\dag^{2^{i-1}}}$ can be re-use to compute $\delta^{\dag^{2^{i+1}}}$. Thus, all the computation can be done using $O(N^2)$ space.
\end{proof}

\todo{Comparer au cas général}

%#############################################################################################################%

\subsection*{Question 6}

%#############################################################################################################%

\subsection*{Question 7}

Using the same reasoning than in question 5, for all $0 \leq m, n \leq N-1$ we have:
\begin{equation}
 \label{qsevenrel}
 \begin{split}
    X^t_{m,n} & = \ddeltat (X^0)_{m,n} \\
              & = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X^0_{i,j} \cdot \ddeltat (E^{i,j})_{m,n} \\
              & = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X^0_{i,j} \cdot \ddeltat (E^{0,0})_{m-i,n-i} \\
              & = \sum_{i=0}^{N-1} \sum_{j=0}^{N-1} X^0_{i,j} \cdot Z^t_{m-i,n-i} \\
 \end{split}
\end{equation}

%#############################################################################################################%

\subsection*{Question 8}

See the implementation in file \texttt{sparse.c}.

%#############################################################################################################%

\subsection*{Question 9}

%#############################################################################################################%
%#############################################################################################################%

\section{Thermal reservoirs}

%#############################################################################################################%

\subsection*{Question 10}
 
\begin{ex}
  The following configuration $X^0$ is a fixed point with one constant (in blue):
  
  \[\begin{array}{ | c | c | c | c | c |} \hline
    0 & 0 & 0 & 0 & 0\\ \hline
    0 & 0 & 0 & 0 & 0\\ \hline
    0 & 0 & \cellcolor{blue!50} 0 & 0 & 0\\ \hline
    0 & 0 & 0 & 0 & 0\\ \hline
    0 & 0 & 0 & 0 & 0\\ \hline
  \end{array}\]
\end{ex}

\begin{ex}
  The following configuration $X^0$ is a fixed point with two constants (in blue):
  
  \[\begin{array}{ | c | c | c | c | c |} \hline
    1 & 2 & 0 & -2 & -1\\ \hline
    2 & 5 & 0 & -5 & -2\\ \hline
    4 & \cellcolor{blue!50} 16 & 0 & \cellcolor{blue!50}  -16 & -4\\ \hline
    2 & 5 & 0 & -5 & -2\\ \hline
    1 & 2 & 0 & -2 & -1\\ \hline
  \end{array}\]
\end{ex}

%%%%%%%%%%%%%%%%%%%%%%%%

\begin{defi}
  We denote $\xinf$ the limit of $(X^t)$ if it exists (i.e. $(X^t)$ converges).
\end{defi}

\begin{lemma}
 \label{fix}
 For each sequence $(X^t)$, if $\xinf$ exists then it is a fixed point.
\end{lemma}

\begin{proof}
  Let us assume that $\xinf$ exists. By definition, for all position $X_{i,j}$ that is not a constant:
   \[\begin{split}
      \lim_{t \rightarrow \infty} \ddeltat(X)_{i,j} & = \xinf_{i,j} \\
        & = \lim_{t \rightarrow \infty} \left( (1-p) \cdot \delta^{\dag^{t-1}}(X)_{i,j} + p \cdot \frac{\delta^{\dag^{t-1}}(X)_{i,j+1} + \delta^{\dag^{t-1}}(X)_{i+1,j} + \delta^{\dag^{t-1}}(X)_{i-1,j} + \delta^{\dag^{t-1}}(X)_{i,j-1}}{4} \right) \\
        & = (1-p) \cdot (\lim_{t \rightarrow \infty} \delta^{\dag^{t-1}}(X)_{i,j}) + p \cdot \frac{(\lim_{t \rightarrow \infty} \delta^{\dag^{t-1}}(X)_{i,j+1}) + (\lim_{t \rightarrow \infty} \delta^{\dag^{t-1}}(X)_{i+1,j})}{4}\\
        & \qquad + p \cdot \frac{(\lim_{t \rightarrow \infty} \delta^{\dag^{t-1}}(X)_{i-1,j}) + (\lim_{t \rightarrow \infty} \delta^{\dag^{t-1}}(X)_{i,j-1})}{4} \\
        & = (1-p) \cdot \xinf_{i,j} + p \cdot \frac{\xinf_{i+1,j} + \xinf_{i,j+1} + \xinf_{i-1,j} + \xinf_{i,j-1}}{4}
 \end{split}\] 

Since $\xinf_{i,j} = (1-p) \cdot \xinf_{i,j} + p \cdot \frac{\xinf_{i+1,j} + \xinf_{i,j+1} + \xinf_{i-1,j} + \xinf_{i,j-1}}{4}$, $\xinf$ is a fixed point.

\end{proof}

\begin{lemma}
 \label{aver}
 If $X$ is a fixed point then for each position $X_{i,j}$ that is not a constant we have : 
\[ X_{i,j} = \frac{X_{i,j+1} + X_{i+1,j} + X_{i-1,j} + X_{i,j-1}}{4} \]
\end{lemma}

\begin{proof}
  If $X$ is a fixed point then for each position $X_{i,j}$ that is not a constant:
  \[ X_{i,j} = (1-p) \cdot X_{i,j} + p \cdot \frac{X_{i,j+1} + X_{i+1,j} + X_{i-1,j} + X_{i,j-1}}{4} \]
  
  If we remove $X_{i,j}$ from both side of this equality and then we simplify it by $p$ ($p \neq 0$), we obtain the lemma.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%

\begin{lemma}
  \label{conservative}
  If $X$ is configuration without any constant then for all t the sum of all values in $\delta^{\dag^{t+1}}$ is equal to the sum of all values in $\delta^{\dag^t}$.
\end{lemma}

\begin{proof}
  We directly obtain that:
  \[\begin{split}
    \sum_{i,j} \delta^{\dag^{t+1}}(X)_{i,j} & = \sum_{i,j} (1-p) \cdot \delta^{\dag^t}(X)_{i,j} + p \cdot \frac{\ddeltat(X)_{i+1,j} + \ddeltat(X)_{i,j+1} + \ddeltat(X)_{i-1,j} + \ddeltat(X)_{i,j-1}}{4} \\
        & = \sum_{i,j} \delta^{\dag^t}(X)_{i,j}
  \end{split} \]
\end{proof}

\begin{prop}
  \label{limnoc}
  Let $X^0$ be a configuration without any constant. If it exists, the limit of $(X^t)$ is $\overline{X^0}$ (the average value of all cells of $X^0$).
\end{prop}

\begin{proof}
  We assume the limit $\xinf$ of $(X_t)$ exists.
  
  First of all, we prove that all the values of $\xinf$ are equal. 
  
  Let us consider a value $d$ contained into $\xinf$ and assume not all the cells of $\xinf$ are equal to $d$.
  
  \textbf{First case} There exists a cell in $\xinf$ that contains a value strictly lower than $d$. We consider a cell $C$ of $\xinf$ containing the lowest value $e$ of $\xinf$ and such that one of its 4 neighbours is different from $e$ (at least one cell contains $d > e$, so $C$ exists). According to lemmas \ref{fix} and \ref{aver}, the value of $C$ must be the average of its 4 neighbours. Since $e$ is the lowest value of $\xinf$ and one of the neighbours of $C$ contains a value different from $e$ (so strictly greater than $e$), $C$ cannot contains the average of its 4 neighbours. \underline{It is absurd.}

  \textbf{Second case} There exists a cell in $\xinf$ that contains a value strictly greater than $d$. As previously, we prove \underline{it is absurd}.
  
  Finally, it is absurd that one of the cells of $\xinf$ contains a value different from $d$. All the cells of $\xinf$ must be equal.
  
  According to lemma \ref{conservative} the sum of all values does not change at any step of the computation. Thus, all the cells of $x^{\infty}$ must be equal to the average value of all the initial cells in $X^0$.  
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{prop}
  \label{twocst}
  Let $X^0$ be a configuration with only one constant $c$. If it exists, the limit of $(X^t)$ is the configuration with all its cells equal to $c$.
\end{prop}

\begin{proof}
  We assume the limit $\xinf$ of $(X_t)$ exists.
  
  As in property \ref{limnoc}, we prove by contradiction that all the cells of $\xinf$ must be equal to $c$, in the corresponding proof we choose $c$ for the value $d$ and the corresponding cell $C$ (that is supposed to contain the lowest or greatest value of the configuration, different from $c=d$) cannot be a constant cell.
\end{proof}

%#############################################################################################################%

\subsection*{Question 11}

 \begin{prop}
    For a \textit{p-average automaton} with constants, $\ddelta$ can be non-linear.
 \end{prop}

 \begin{proof}
   Let's consider the following local configuration:
   \[\begin{array}{ | c | c | c |} \hline
    0 & 0 & 0 \\ \hline
    0 & 1 & 0 \\ \hline
    0 & 0 & 0 \\ \hline
  \end{array}\]
  
  We assume that 1 is a constant, but 0 not. We take $p=0.5$.
  
  We have:
 \[\begin{split}
 \delta \left(\begin{array}{ | c | c | c |} \hline
  0 & 0 & 0 \\ \hline
  0 & 1 & 0 \\ \hline
  0 & 0 & 0 \\ \hline
 \end{array} + \begin{array}{ | c | c | c |} \hline
  0 & 0 & 0 \\ \hline
  0 & 1 & 0 \\ \hline
  0 & 0 & 0 \\ \hline
 \end{array} \right) & = \delta \left(\begin{array}{ | c | c | c |} \hline
  0 & 0 & 0 \\ \hline
  0 & 2 & 0 \\ \hline
  0 & 0 & 0 \\ \hline
 \end{array} \right) \\
		     & = 0.5 \cdot 2 = 1    
 \end{split}\]  
  
  However:
 \[\begin{split}
 \delta \left(\begin{array}{ | c | c | c |} \hline
  0 & 0 & 0 \\ \hline
  0 & 1 & 0 \\ \hline
  0 & 0 & 0 \\ \hline
 \end{array}\right) + \delta \left(\begin{array}{ | c | c | c |} \hline
  0 & 0 & 0 \\ \hline
  0 & 1 & 0 \\ \hline
  0 & 0 & 0 \\ \hline
 \end{array} \right) & = 1 + 1 = 2
 \end{split}\]  
  
 $\delta$ is not linear, and so $\ddelta$ too. This result proves that $\ddelta$ can be non-linear for a \textit{p-average automaton} with constants.
 \end{proof}

%#############################################################################################################%

\subsection*{Question 12}

%#############################################################################################################%

\subsection*{Question 13}
 
See the implementation in file \texttt{constants.c}.

%#############################################################################################################%
%#############################################################################################################%
%#############################################################################################################%

\end{document}
